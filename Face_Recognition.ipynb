{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "137b11db-cbc8-4bf5-9d49-3c90bc1cbb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras.layers import Lambda, Flatten, Dense\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81cad7d9-e4c3-4d4e-9726-9df205257d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71e578e3-b2ca-4e5b-a203-6035d9496e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867e944-b538-45a7-8c06-77d017bc0b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "json_file = open(r'D:\\DLS\\model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "model.load_weights('keras-facenet-h5/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66874149-dcf9-4d57-a02a-435c63ebc0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-facenet\n",
      "  Downloading keras-facenet-0.3.2.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting mtcnn (from keras-facenet)\n",
      "  Downloading mtcnn-0.1.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: keras>=2.0.0 in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mtcnn->keras-facenet) (3.4.1)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mtcnn->keras-facenet) (4.10.0.84)\n",
      "Requirement already satisfied: absl-py in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=2.0.0->mtcnn->keras-facenet) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=2.0.0->mtcnn->keras-facenet) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=2.0.0->mtcnn->keras-facenet) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=2.0.0->mtcnn->keras-facenet) (0.0.7)\n",
      "Requirement already satisfied: h5py in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=2.0.0->mtcnn->keras-facenet) (3.10.0)\n",
      "Requirement already satisfied: optree in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=2.0.0->mtcnn->keras-facenet) (0.12.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=2.0.0->mtcnn->keras-facenet) (0.3.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=2.0.0->mtcnn->keras-facenet) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optree->keras>=2.0.0->mtcnn->keras-facenet) (4.10.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=2.0.0->mtcnn->keras-facenet) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=2.0.0->mtcnn->keras-facenet) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mega store\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=2.0.0->mtcnn->keras-facenet) (0.1.2)\n",
      "Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.5/2.3 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.8/2.3 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 1.3/2.3 MB 1.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.6/2.3 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.3 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.3 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 1.3 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: keras-facenet\n",
      "  Building wheel for keras-facenet (setup.py): started\n",
      "  Building wheel for keras-facenet (setup.py): finished with status 'done'\n",
      "  Created wheel for keras-facenet: filename=keras_facenet-0.3.2-py3-none-any.whl size=10387 sha256=9e5512cc1605555d5fcc0223372569d5911757b15a41e40df039621faaaba528\n",
      "  Stored in directory: c:\\users\\mega store\\appdata\\local\\pip\\cache\\wheels\\05\\b0\\f5\\19ac49fedc10b1df3ee56b096edbcfa39d45794fccc6bcdbbf\n",
      "Successfully built keras-facenet\n",
      "Installing collected packages: mtcnn, keras-facenet\n",
      "Successfully installed keras-facenet-0.3.2 mtcnn-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-facenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aa3c225-28e9-42fd-9c3b-97bdc3f9952b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.1'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09595e67-d474-40c9-925a-cb6a6b48b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fc23227-ad2d-49e7-807c-ee3dec9b85ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Mega Store\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:192: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras_facenet import FaceNet\n",
    "\n",
    "embedder = FaceNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c67fb1e-0e85-4b48-a917-071a7ef94209",
   "metadata": {},
   "source": [
    "## **Download Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5949259-60a4-45b2-be6d-4fb0213ad2ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_facenet.FaceNet at 0x20765982900>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "589a5249-e7c4-4152-a0d6-8789d9f607ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss as defined by formula (3)\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras, you don't need it in this function.\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor, positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    # YOUR CODE STARTS HERE (≈ 4 lines)\n",
    "    # Step 1: Compute the (encoding) distance between the anchor and the positive\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)),axis=-1)\n",
    "    # Step 2: Compute the (encoding) distance between the anchor and the negative\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)),axis=-1)\n",
    "    # Step 3: subtract the two previous distances and add alpha.\n",
    "    basic_loss = tf.maximum(tf.add(tf.subtract(pos_dist,neg_dist),alpha),0)\n",
    "    # Step 4: Take the maximum of basic_loss and 0.0. Sum over the training examples.\n",
    "    loss = tf.reduce_sum(basic_loss)\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db572544-4442-48a8-aad4-25ea613951dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding(image_path, model):\n",
    "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(160, 160))\n",
    "    img = np.around(np.array(img) / 255.0, decimals=12)\n",
    "    x_train = np.expand_dims(img, axis=0)\n",
    "    detections = model.extract(image_path, threshold=0.95)\n",
    "    return detections[0]['embedding']/ np.linalg.norm(detections[0]['embedding'], ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e0d9c0dd-9e9a-4f08-bf7a-f04151f1256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n"
     ]
    }
   ],
   "source": [
    "x=img_to_encoding(r'D:\\DLS\\GearedorNot\\Not Wearing Safety Gear\\X.jpg',embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "314ccb5c-7af1-4660-9d9d-6f490a9ea019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dacd7e2c-b985-415a-8af3-60914b9a33f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.86323018e-02, -8.84403661e-03, -7.77105540e-02, -2.08631717e-02,\n",
       "       -6.86477497e-02, -8.33999179e-03, -9.69568342e-02,  5.70046343e-02,\n",
       "       -2.92030945e-02, -3.81327309e-02, -7.92554207e-03, -3.44295957e-04,\n",
       "       -1.98372249e-02, -4.10851724e-02, -1.20104151e-03, -2.21584160e-02,\n",
       "        5.95761510e-03, -3.94823104e-02,  5.53067885e-02, -2.62466855e-02,\n",
       "        7.70026371e-02,  1.37705738e-02,  2.16660537e-02,  5.65438010e-02,\n",
       "        2.51344163e-02,  4.44295676e-03,  2.87167300e-02,  5.23883514e-02,\n",
       "       -4.65062819e-03,  7.58266672e-02, -2.61928653e-04, -2.02011634e-02,\n",
       "        7.17402902e-03, -3.22209857e-02,  5.13674086e-03,  3.74239832e-02,\n",
       "       -4.37760539e-02,  4.29334603e-02,  5.92274368e-02,  3.27288844e-02,\n",
       "       -1.70678981e-02,  6.79221153e-02,  9.14747268e-03,  2.79354211e-02,\n",
       "       -2.20181867e-02, -1.53188535e-03, -5.67106232e-02, -5.28031029e-04,\n",
       "       -5.23549691e-02,  7.75643112e-03, -6.98656589e-02,  1.58944670e-02,\n",
       "        1.73682943e-02, -3.68079869e-03, -2.41371673e-02,  1.15586475e-01,\n",
       "        6.54423609e-02,  4.54475805e-02,  9.43795666e-02, -5.03757223e-02,\n",
       "        2.68564839e-02,  7.84531608e-02, -4.48124707e-02, -5.35688549e-02,\n",
       "        9.09086540e-02,  1.06241487e-01,  4.01582383e-02, -6.42285496e-02,\n",
       "       -2.33235732e-02,  2.79088374e-02, -9.27734468e-03, -3.77721759e-03,\n",
       "        1.66950151e-02,  1.41106658e-02, -1.76804531e-02,  2.09326874e-02,\n",
       "       -9.80561748e-02, -5.61840134e-03, -2.60201842e-02,  5.33517450e-02,\n",
       "        1.96830556e-02,  7.47202212e-05,  1.92145479e-03,  9.61391181e-02,\n",
       "        6.37719929e-02, -7.18953609e-02, -3.65635939e-02,  1.02472238e-01,\n",
       "       -7.10940510e-02, -2.66018920e-02,  1.47206187e-02, -3.67525928e-02,\n",
       "        4.22702208e-02, -5.53616695e-02, -1.18205016e-02, -6.26037121e-02,\n",
       "       -8.55041854e-03, -1.56736895e-02,  3.07988264e-02,  3.93964984e-02,\n",
       "        1.02533959e-02, -2.10062936e-02, -2.38174163e-02,  2.66529154e-02,\n",
       "        3.18116806e-02,  4.35096659e-02,  6.56857714e-03, -3.77220404e-03,\n",
       "        1.87762827e-02, -2.32069800e-03, -9.03771631e-03,  4.25037742e-02,\n",
       "       -4.33655754e-02, -5.70528693e-02, -1.85655467e-02, -4.39827740e-02,\n",
       "       -1.96189620e-02,  3.29319276e-02, -1.29771242e-02, -2.68404861e-03,\n",
       "       -1.05083674e-01, -4.13420573e-02, -3.81755605e-02,  5.37560880e-02,\n",
       "        7.53433863e-03,  3.72489281e-02,  3.15018333e-02,  2.38607004e-02,\n",
       "       -1.77112781e-02, -1.18733980e-02, -9.45196152e-02, -1.51319588e-02,\n",
       "        4.81582731e-02, -4.36158925e-02, -4.97379666e-03,  5.81829958e-02,\n",
       "        4.37570699e-02,  7.42937922e-02,  1.67786051e-02,  2.52271700e-03,\n",
       "       -3.04444041e-02, -6.03356250e-02,  1.36961062e-02, -1.21874232e-02,\n",
       "        2.42279638e-02, -4.51479517e-02, -6.91758767e-02,  3.08093708e-03,\n",
       "        2.65124477e-02,  2.80666165e-02,  1.79967210e-02, -8.68758745e-03,\n",
       "        1.70265436e-02, -3.73396470e-04,  1.69070642e-02,  2.01127417e-02,\n",
       "        5.61722927e-02,  7.96626601e-03,  6.42633706e-04, -2.32760813e-02,\n",
       "        6.10091239e-02, -3.06042135e-02, -1.67391123e-03,  3.82610634e-02,\n",
       "        4.49647196e-02,  1.43707171e-03,  1.93767957e-02, -4.01492752e-02,\n",
       "       -5.85634203e-04, -7.87105504e-03, -8.96767713e-03, -3.03084292e-02,\n",
       "       -2.37790328e-02, -5.04796691e-02, -2.83649266e-02, -2.81339861e-03,\n",
       "        6.92743286e-02, -1.74390972e-02, -3.33931111e-02, -3.80137786e-02,\n",
       "        2.89205788e-03, -8.48336220e-02, -1.42850270e-02,  2.31929552e-02,\n",
       "       -2.25777142e-02,  6.68739304e-02, -4.16646376e-02,  8.29797536e-02,\n",
       "       -4.68420237e-02, -2.47595981e-02,  1.83513388e-02, -5.31024151e-02,\n",
       "        3.29245888e-02, -3.39229405e-02,  4.02383916e-02,  3.93623821e-02,\n",
       "        4.01725210e-02,  4.94385362e-02, -3.56844403e-02,  1.04887418e-01,\n",
       "       -4.41463701e-02,  1.09117121e-01, -3.02852560e-02, -6.23682775e-02,\n",
       "        3.38662863e-02,  6.35722727e-02, -5.89172430e-02, -6.61971048e-02,\n",
       "        1.78511404e-02,  3.94510552e-02,  6.66520596e-02,  7.63214454e-02,\n",
       "       -3.60853486e-02,  2.34685168e-02, -8.33752677e-02,  2.83726975e-02,\n",
       "       -2.99558658e-02, -2.74843741e-02,  4.15653363e-03, -4.90432121e-02,\n",
       "       -2.50979438e-02, -1.41075347e-02, -2.18662228e-02,  2.53903400e-02,\n",
       "        4.92259907e-03, -4.86052856e-02, -5.39902262e-02, -3.53766717e-02,\n",
       "       -2.67133322e-02,  6.10972231e-04, -1.15283846e-03,  3.69399856e-03,\n",
       "        7.69220875e-04, -6.79838732e-02,  4.69948165e-02, -3.22451703e-02,\n",
       "        7.75516257e-02,  1.64954420e-02, -7.13263303e-02, -5.85622303e-02,\n",
       "        5.01113907e-02,  2.15906668e-02,  2.69967820e-02, -2.46247929e-02,\n",
       "       -2.50292681e-02,  6.63859621e-02, -7.17275515e-02,  8.57581422e-02,\n",
       "       -3.14235985e-02, -1.37439389e-02, -9.89753474e-03,  2.33175363e-02,\n",
       "       -6.43631518e-02,  1.36300232e-02,  8.79686102e-02,  2.05937983e-03,\n",
       "        3.94035280e-02,  3.28904539e-02,  9.58967656e-02,  8.29108711e-03,\n",
       "       -4.60800948e-03, -8.47686753e-02,  5.17370040e-03,  2.14093830e-02,\n",
       "       -9.07124765e-03, -1.42911989e-02,  1.76811982e-02,  1.67324655e-02,\n",
       "       -5.04271649e-02,  3.04804239e-02, -3.29282470e-02, -1.26195392e-02,\n",
       "       -4.42921668e-02,  1.72515381e-02, -3.74242105e-02,  2.84267161e-02,\n",
       "        5.31399716e-03, -2.72016749e-02, -3.17600556e-02, -7.47396797e-02,\n",
       "        7.79136941e-02, -3.22005823e-02,  1.71060823e-02, -5.87388352e-02,\n",
       "        4.48210202e-02,  2.37447172e-02,  1.31773679e-02, -4.38510105e-02,\n",
       "        2.41798144e-02,  3.97318974e-03,  5.32566421e-02, -1.44100692e-02,\n",
       "        5.30738523e-03,  1.32019157e-02, -5.96063361e-02, -5.59187308e-02,\n",
       "        5.04099987e-02,  3.02848257e-02,  2.15622261e-02,  5.96456639e-02,\n",
       "        1.83108170e-02,  1.39679043e-02, -8.77847522e-03, -6.19426258e-02,\n",
       "       -2.49950849e-02,  1.86363496e-02,  5.91220148e-02, -1.70654692e-02,\n",
       "        1.14618745e-02, -4.63345349e-02, -2.35826075e-02, -6.84511885e-02,\n",
       "       -1.09482752e-02, -4.47594859e-02, -6.38123080e-02,  2.82266550e-02,\n",
       "       -3.72032076e-02, -3.30515690e-02,  1.63771454e-02,  1.81322042e-02,\n",
       "       -3.58249955e-02, -4.35833223e-02, -3.68884616e-02, -2.05336064e-02,\n",
       "       -2.82021780e-02,  2.79881433e-02,  5.65815382e-02, -2.99724434e-02,\n",
       "        2.46413648e-02,  4.48010787e-02,  4.06807922e-02, -3.32421958e-02,\n",
       "       -6.71667010e-02,  2.70554014e-02,  5.33370227e-02, -1.78393796e-02,\n",
       "       -1.17116407e-01, -3.65935266e-02,  6.32571662e-03, -2.52517965e-02,\n",
       "        3.95654105e-02,  3.66339609e-02,  2.28825510e-02,  3.29216570e-02,\n",
       "       -9.33959633e-02, -1.31750572e-02,  4.48531248e-02, -3.08006350e-03,\n",
       "        2.40191240e-02,  1.00247622e-01, -1.82416998e-02,  1.09984921e-02,\n",
       "       -5.61550492e-03, -7.38528185e-03, -6.34896681e-02, -4.01401483e-02,\n",
       "       -1.46301538e-02, -4.96463059e-03, -1.11630224e-02, -1.39269121e-02,\n",
       "       -1.44622345e-02,  4.68566567e-02, -6.19658753e-02, -3.38553190e-02,\n",
       "        3.23936567e-02,  6.45509437e-02,  1.05031237e-01, -2.55199932e-02,\n",
       "       -5.42207509e-02, -3.39231715e-02, -4.49458025e-02, -7.92000163e-03,\n",
       "        5.80254477e-04,  6.32086582e-03,  5.78358918e-02, -5.28332517e-02,\n",
       "       -3.64995450e-02, -5.17915115e-02, -6.22007251e-03, -3.39896120e-02,\n",
       "        5.69591299e-02, -5.01686558e-02, -2.32486781e-02,  4.71148528e-02,\n",
       "       -2.31939983e-02, -4.80960542e-03,  1.10996939e-01, -5.83076887e-02,\n",
       "        4.12585326e-02,  2.79253386e-02,  6.08531497e-02,  8.50088021e-04,\n",
       "       -1.43030460e-03, -8.05681273e-02,  3.56233977e-02,  5.73098660e-02,\n",
       "        2.37833168e-02, -1.83301456e-02, -2.50857305e-02, -1.14644375e-02,\n",
       "        4.97280993e-02,  5.50320372e-02,  9.35190078e-03, -4.34002057e-02,\n",
       "        6.04389375e-03,  6.18362240e-02, -4.40844186e-02, -1.93158723e-02,\n",
       "        6.68424414e-03, -2.54694540e-02,  1.07421968e-02,  1.13255680e-02,\n",
       "        7.56325014e-03,  1.33160129e-02, -1.61414687e-02, -1.88036859e-02,\n",
       "        7.99795091e-02,  2.41680611e-02, -6.18484579e-02,  5.62400185e-02,\n",
       "       -9.07118060e-03,  1.38272122e-02, -2.32408699e-02,  8.47836863e-03,\n",
       "        1.33992629e-02, -7.50241578e-02,  6.09649755e-02, -1.98298395e-02,\n",
       "        6.96127266e-02,  3.02996952e-02,  2.30543735e-03,  1.22865255e-03,\n",
       "        7.96100963e-03, -1.36768408e-02, -4.53320555e-02, -1.84537712e-02,\n",
       "        5.84486201e-02,  4.41033840e-02,  2.50151232e-02, -1.57531388e-02,\n",
       "        6.47752732e-02,  6.87088165e-03, -1.83533542e-02,  2.99285445e-02,\n",
       "        6.60876036e-02,  5.23686931e-02, -3.92167307e-02,  5.25033884e-02,\n",
       "       -8.32747668e-02,  1.50386011e-02,  6.55884594e-02,  5.83916679e-02,\n",
       "        2.57160980e-02,  2.98463763e-03,  3.91219603e-03, -3.52749787e-02,\n",
       "        3.78003158e-02,  3.14391404e-02,  7.31348097e-02,  1.55893471e-02,\n",
       "       -5.75489458e-03,  3.59641621e-03, -3.79251912e-02, -4.75333706e-02,\n",
       "        6.00805990e-02, -2.26230593e-03, -7.95497298e-02,  3.39617729e-02,\n",
       "       -1.23056658e-02,  2.03626100e-02, -1.34441117e-02,  7.74115771e-02,\n",
       "        8.99712816e-02, -9.98951569e-02, -4.43337066e-03, -7.41528422e-02,\n",
       "       -3.31402123e-02, -3.16462517e-02, -1.28765944e-02, -2.47807074e-02,\n",
       "       -1.78833567e-02, -4.82065193e-02,  5.19977249e-02,  3.52738202e-02,\n",
       "        3.24005969e-02,  9.87228658e-03, -3.31423990e-02,  4.13904786e-02,\n",
       "        1.71009377e-02, -3.24244723e-02,  1.10884838e-01, -5.43651655e-02,\n",
       "        1.78809911e-02,  6.57998994e-02, -4.27042842e-02,  2.68319473e-02,\n",
       "        8.29857364e-02, -7.38942772e-02, -2.89418790e-02, -6.39087334e-02,\n",
       "       -6.99565709e-02,  1.05124384e-01, -3.62459756e-02,  9.17826369e-02,\n",
       "       -5.29957712e-02, -3.04134022e-02,  5.30512780e-02,  2.65876744e-02,\n",
       "       -9.18635949e-02,  8.22939873e-02,  4.75073904e-02, -4.46369760e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f82d2b03-8d2c-4601-8fbd-25faa709af49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step\n"
     ]
    }
   ],
   "source": [
    "database = {}\n",
    "database[\"Fayad\"] = img_to_encoding(r\"D:\\DLS\\Fayad.jpg\",embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3bed2b88-269e-4849-9b5f-286b4de68012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify(image_path, identity, database, model):\n",
    "    \"\"\"\n",
    "    Function that verifies if the person on the \"image_path\" image is \"identity\".\n",
    "    \n",
    "    Arguments:\n",
    "        image_path -- path to an image\n",
    "        identity -- string, name of the person you'd like to verify the identity. Has to be an employee who works in the office.\n",
    "        database -- python dictionary mapping names of allowed people's names (strings) to their encodings (vectors).\n",
    "        model -- your Inception model instance in Keras\n",
    "    \n",
    "    Returns:\n",
    "        dist -- distance between the image_path and the image of \"identity\" in the database.\n",
    "        door_open -- True, if the door should open. False otherwise.\n",
    "    \"\"\"\n",
    "        \n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    #Step 1: Compute the encoding for the image. Use img_to_encoding() see example above. (≈ 1 line)\n",
    "    encoding = img_to_encoding(image_path,model)\n",
    "    # Step 2: Compute distance with identity's image (≈ 1 line)\n",
    "    dist = np.linalg.norm(encoding - database[identity])\n",
    "    # Step 3: Open the door if dist < 0.7, else don't open (≈ 3 lines)\n",
    "    if dist < 0.7:\n",
    "        print(\"It's \" + str(identity) + \", welcome in!\")\n",
    "        door_open = True\n",
    "    else:\n",
    "        print(\"It's not \" + str(identity) + \", please go away\")\n",
    "        door_open = False\n",
    "\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "        \n",
    "    return dist, door_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cdcd8fa9-dc84-4c48-b06b-547cfd9c7839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
      "It's not Fayad, please go away\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.4769335, False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verify(r\"D:\\DLS\\GearedorNot\\Not Wearing Safety Gear\\theRock.jpeg\", \"Fayad\", database,embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c5f71b56-a519-4011-89d5-0b19228ae33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def who_is_it(image_path, database, model):\n",
    "    \"\"\"\n",
    "    Implements face recognition for the office by finding who is the person on the image_path image.\n",
    "    \n",
    "    Arguments:\n",
    "        image_path -- path to an image\n",
    "        database -- database containing image encodings along with the name of the person on the image\n",
    "        model -- your Inception model instance in Keras\n",
    "    \n",
    "    Returns:\n",
    "        min_dist -- the minimum distance between image_path encoding and the encodings from the database\n",
    "        identity -- string, the name prediction for the person on image_path\n",
    "    \"\"\"\n",
    "    # YOUR CODE STARTS HERE\n",
    "    \n",
    "    ## Step 1: Compute the target \"encoding\" for the image. Use img_to_encoding() see example above. ## (≈ 1 line)\n",
    "    encoding = img_to_encoding(image_path,model)\n",
    "    \n",
    "    ## Step 2: Find the closest encoding ##\n",
    "    # Initialize \"min_dist\" to a large value, say 100 (≈1 line)\n",
    "    min_dist = 100\n",
    "    \n",
    "    #Loop over the database dictionary's names and encodings.\n",
    "    for (name, db_enc) in database.items():\n",
    "        \n",
    "        # Compute L2 distance between the target \"encoding\" and the current db_enc from the database. (≈ 1 line)\n",
    "        dist = np.linalg.norm(encoding - db_enc)\n",
    "\n",
    "        # If this distance is less than the min_dist, then set min_dist to dist, and identity to name. (≈ 3 lines)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    if min_dist > 0.7:\n",
    "        print(\"Not in the database.\")\n",
    "    else:\n",
    "        print (\"it's \" + str(identity) + \", the distance is \" + str(min_dist))\n",
    "        \n",
    "    return min_dist, identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9392be84-56fe-4083-80df-33629a123ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step\n",
      "Not in the database.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7846287, 'Fayad')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "who_is_it(r'D:\\Mega Store\\Pictures\\Camera Roll\\tst.jpg',database,embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "783c9abd-93c5-48aa-ad20-4c2dc9b085d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved at: captured_images\\b0fdcbde-1870-49ed-854f-fbd065167171.jpg\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step\n",
      "it's Fayad, the distance is 0.42182046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.42182046, 'Fayad')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import cv2\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "def capture_and_save_image(save_dir=\"captured_images\", image_name=None):\n",
    "    # Create the directory if it doesn't exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    # Capture image from the default camera\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    # Check if the camera opened successfully\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Could not open video device\")\n",
    "    \n",
    "    # Read a frame from the camera\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Release the camera1\n",
    "    cap.release()\n",
    "    \n",
    "    if not ret:\n",
    "        raise Exception(\"Failed to capture image\")\n",
    "    \n",
    "    # Generate a unique name for the image if not provided\n",
    "    if image_name is None:\n",
    "        image_name = str(uuid.uuid4()) + \".jpg\"\n",
    "    \n",
    "    # Full path to save the image\n",
    "    image_path = os.path.join(save_dir, image_name)\n",
    "    \n",
    "    # Save the image to the specified path\n",
    "    cv2.imwrite(image_path, frame)\n",
    "    \n",
    "    # Return the path to the saved image\n",
    "    return image_path\n",
    "\n",
    "\n",
    "# Example usage\n",
    "image_path = capture_and_save_image()\n",
    "print(f\"Image saved at: {image_path}\")\n",
    "who_is_it(image_path,database,embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faafc72-b634-4fda-acc9-d433ce5a5292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
